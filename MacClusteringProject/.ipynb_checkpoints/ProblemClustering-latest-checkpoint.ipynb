{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_validate,cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectFdr\n",
    "from sklearn.decomposition import PCA\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data as data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemfile = 'problems_2019-03-21.xlsx'\n",
    "df = pd.read_excel(problemfile)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.dropna(axis=1, how='all')\n",
    "data = df.dropna(axis=1, thresh=df.shape[0]*0.90)\n",
    "for col in data:\n",
    "    if len(data[col].value_counts()) < 2:\n",
    "        data = data.drop(col, axis=1)\n",
    "data = data.drop(['Active', 'Known error', 'Problem state', 'State'], axis=1)\n",
    "data['Parent'] = df['Parent']\n",
    "data.to_csv('problem_pdsm_simple.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract keywords from descriptions in full dataset\n",
    "Adds Short Description and Keywords features to above dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    r = Rake(min_length=2, max_length=8)\n",
    "    r.extract_keywords_from_text(text)\n",
    "    return r.get_ranked_phrases()[0:4]\n",
    "data['Keywords'] = data['Short description'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(sorted(data.columns), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load incidents dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents = pd.read_excel('incidents_2019-03-21.xlsx')\n",
    "incidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add assignment group from incidents to problems dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign_groups = incidents[['Problem', 'Assignment group']]\n",
    "# assign_groups = assign_groups.rename(columns={'Problem':'Number'}).drop_duplicates('Number')\n",
    "# # assign_groups.head()\n",
    "# data = data.merge(assign_groups, how='left', on='Number')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get avg, min, and max duration of related incidents for each problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations = incidents[['Problem','Duration']]\n",
    "durations = durations.rename(columns={'Problem':'Number'})\n",
    "durations2 = data[['Number', 'Duration']]\n",
    "durations = durations.merge(durations2, how='left', on='Number')\n",
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# durations.groupby(['Number']).mean()\n",
    "durations['Duration Max'] = durations.Number.map(durations.groupby(['Number'])['Duration'].max())\n",
    "durations['Duration Mean'] = durations.Number.map(durations.groupby(['Number'])['Duration'].mean())\n",
    "durations['Duration Min'] = durations.Number.map(durations.groupby(['Number'])['Duration'].min())\n",
    "durations['Duration Range'] = durations['Duration Max'] - durations['Duration Min']\n",
    "durations = durations.drop_duplicates('Number').drop('Duration', axis=1)\n",
    "durations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations2 = data[['Number', 'Duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(durations, how='left', on='Number')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar keywords within related incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out default types for the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the PRB prefix from the Number column and convert it to a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number'] = data['Number'].map(lambda x: x.lstrip('PRB'))\n",
    "data['Number'] = pd.to_numeric(data['Number'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority, Impact, and Urgency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the first character (number) from each and convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Priority'] = data['Priority'].map(lambda x: x[0])\n",
    "data['Priority'] = pd.to_numeric(data['Priority'])\n",
    "\n",
    "data['Impact'] = data['Impact'].map(lambda x: x[0])\n",
    "data['Impact'] = pd.to_numeric(data['Impact'])\n",
    "\n",
    "data['Urgency'] = data['Urgency'].map(lambda x: x[0])\n",
    "data['Urgency'] = pd.to_numeric(data['Urgency'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out category counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Business service'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Company'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Problem Manager'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Assignment group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut categories with low counts and add together to make an \"Other\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(lambda x: x.mask(x.map(x.value_counts())<10, 'Other') if x.name=='Business service' else x)\n",
    "data = data.apply(lambda x: x.mask(x.map(x.value_counts())<10, 'Other') if x.name=='Company' else x)\n",
    "data = data.apply(lambda x: x.mask(x.map(x.value_counts())<10, 'Other') if x.name=='Problem Manager' else x)\n",
    "data = data.apply(lambda x: x.mask(x.map(x.value_counts())<10, 'Other') if x.name=='Type' else x)\n",
    "data = data.apply(lambda x: x.mask(x.map(x.value_counts())<10, 'Other') if x.name=='Assignment group' else x)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical fields to be a category type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Business service'] = data['Business service'].astype('category')\n",
    "data['Category'] = data['Category'].astype('category')\n",
    "data['Company'] = data['Company'].astype('category')\n",
    "data['Problem Manager'] = data['Problem Manager'].astype('category')\n",
    "data['Type'] = data['Type'].astype('category')\n",
    "data['Assignment group'] = data['Assignment group'].astype('category')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Created column to a datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Created'] = data['Created'].astype('datetime64[ns]')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Created by column to a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Created by'] = pd.to_numeric(data['Created by'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there may be some that have \"admin\" before the id number. I am just going to remove this prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Created by'] = data['Created by'].map(lambda x: x.lstrip('admin'))\n",
    "data['Created by'] = pd.to_numeric(data['Created by'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impacted OpCos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Impacted OpCos column into list of OpCos instead of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Impacted OpCos'] = data['Impacted OpCos'].map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird.. Let's look for that float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Impacted OpCos'].apply(np.isreal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the NaNs are the problem. Convert NaNs to empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Impacted OpCos'] = data['Impacted OpCos'].replace(np.nan, '', regex=True)\n",
    "data[data['Impacted OpCos'].apply(np.isreal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no longer any NaNs, so let's try the split again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Impacted OpCos'] = data['Impacted OpCos'].map(lambda x: x.split(\",\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the list, but we can't do anything with the list. Let's convert to dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data['Impacted OpCos'].apply(pd.Series).stack()).sum(level=0).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That will take a lot of further processing, so I am going to drop that for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Impacted OpCos', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Parent column to a boolean Has Parent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Has Parent'] = data['Parent'].map(lambda x: not(np.isreal(x)))\n",
    "data = data.drop('Parent', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all columns have a proper data type; let's drop the NaNs and look at our clean data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding categorical time of day feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import *\n",
    "def convert_datetime(ts):\n",
    "    h = ts.hour\n",
    "    return ('morning' if 5 <= h < 12\n",
    "        else 'afternoon' if 12 <= h < 17\n",
    "        else 'evening' if 17 <= h < 21\n",
    "        else 'night')\n",
    "\n",
    "data.insert(loc=6, column='Created Time', value=data['Created'].apply(convert_datetime))\n",
    "data['Created Time'] = data['Created Time'].astype('category')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export most recently cleaned data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('problems_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up dataset with NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_data = pd.read_csv('problems_cleaned_withna.csv')\n",
    "prob_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
